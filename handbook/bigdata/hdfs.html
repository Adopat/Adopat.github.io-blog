<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>第二章 HDFS | Adopat的博客</title>
    <meta name="generator" content="VuePress 1.9.9">
    <link rel="icon" href="/blog/logo.jpeg">
    <link rel="manifest" href="/blog/logo.jpeg">
    <link rel="apple-touch-icon" href="/blog/logo.jpeg">
    <link rel="mask-icon" href="/blog/logo.jpeg" color="#3eaf7c">
    <meta name="description" content="长路漫漫，唯键作伴">
    <meta http-quiv="pragma" cotent="no-cache">
    <meta http-quiv="expires" cotent="0">
    <meta http-quiv="pragma" cotent="no-cache, must-revalidate">
    <meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no">
    <meta charset="utf-8">
    
    <link rel="preload" href="/blog/assets/css/0.styles.c74f429a.css" as="style"><link rel="preload" href="/blog/assets/js/app.f600c34c.js" as="script"><link rel="preload" href="/blog/assets/js/3.1aae9359.js" as="script"><link rel="preload" href="/blog/assets/js/1.ae8a88ec.js" as="script"><link rel="preload" href="/blog/assets/js/44.e50bce95.js" as="script"><link rel="prefetch" href="/blog/assets/js/10.d3b9c11d.js"><link rel="prefetch" href="/blog/assets/js/11.acb152df.js"><link rel="prefetch" href="/blog/assets/js/12.c8509742.js"><link rel="prefetch" href="/blog/assets/js/13.811061e2.js"><link rel="prefetch" href="/blog/assets/js/14.db6b0e70.js"><link rel="prefetch" href="/blog/assets/js/15.2ce37a4a.js"><link rel="prefetch" href="/blog/assets/js/16.b3452aec.js"><link rel="prefetch" href="/blog/assets/js/17.dc1a8405.js"><link rel="prefetch" href="/blog/assets/js/18.f03199ab.js"><link rel="prefetch" href="/blog/assets/js/19.bb1e396b.js"><link rel="prefetch" href="/blog/assets/js/20.4e2d0adb.js"><link rel="prefetch" href="/blog/assets/js/21.b67291e2.js"><link rel="prefetch" href="/blog/assets/js/22.057ea7c4.js"><link rel="prefetch" href="/blog/assets/js/23.70da62c2.js"><link rel="prefetch" href="/blog/assets/js/24.8cd404c5.js"><link rel="prefetch" href="/blog/assets/js/25.e637bb66.js"><link rel="prefetch" href="/blog/assets/js/26.bb3896ad.js"><link rel="prefetch" href="/blog/assets/js/27.021e6dc3.js"><link rel="prefetch" href="/blog/assets/js/28.6949fbc1.js"><link rel="prefetch" href="/blog/assets/js/29.6c652456.js"><link rel="prefetch" href="/blog/assets/js/30.f23dfdea.js"><link rel="prefetch" href="/blog/assets/js/31.3dcf5164.js"><link rel="prefetch" href="/blog/assets/js/32.b554bb64.js"><link rel="prefetch" href="/blog/assets/js/33.6ba9e186.js"><link rel="prefetch" href="/blog/assets/js/34.2ae1eb6a.js"><link rel="prefetch" href="/blog/assets/js/35.1fe5b5a2.js"><link rel="prefetch" href="/blog/assets/js/36.614599d6.js"><link rel="prefetch" href="/blog/assets/js/37.311ebd2c.js"><link rel="prefetch" href="/blog/assets/js/38.50bccc51.js"><link rel="prefetch" href="/blog/assets/js/39.fc5b9233.js"><link rel="prefetch" href="/blog/assets/js/4.1dd123be.js"><link rel="prefetch" href="/blog/assets/js/40.f5520796.js"><link rel="prefetch" href="/blog/assets/js/41.a23e6477.js"><link rel="prefetch" href="/blog/assets/js/42.1ad13e0e.js"><link rel="prefetch" href="/blog/assets/js/43.1235eb55.js"><link rel="prefetch" href="/blog/assets/js/45.96aaada5.js"><link rel="prefetch" href="/blog/assets/js/46.f656cba5.js"><link rel="prefetch" href="/blog/assets/js/47.e170369f.js"><link rel="prefetch" href="/blog/assets/js/48.95e08a63.js"><link rel="prefetch" href="/blog/assets/js/49.eaea0707.js"><link rel="prefetch" href="/blog/assets/js/5.4cb445b4.js"><link rel="prefetch" href="/blog/assets/js/50.b1126e4d.js"><link rel="prefetch" href="/blog/assets/js/51.c28c85ff.js"><link rel="prefetch" href="/blog/assets/js/52.431357ea.js"><link rel="prefetch" href="/blog/assets/js/53.be380102.js"><link rel="prefetch" href="/blog/assets/js/54.5877a497.js"><link rel="prefetch" href="/blog/assets/js/55.e1d5dddb.js"><link rel="prefetch" href="/blog/assets/js/56.1962bc1e.js"><link rel="prefetch" href="/blog/assets/js/57.b7d9dbdd.js"><link rel="prefetch" href="/blog/assets/js/58.b5d9b427.js"><link rel="prefetch" href="/blog/assets/js/59.e07757a4.js"><link rel="prefetch" href="/blog/assets/js/6.e02ce0fc.js"><link rel="prefetch" href="/blog/assets/js/60.50d5d207.js"><link rel="prefetch" href="/blog/assets/js/61.2bdc68d5.js"><link rel="prefetch" href="/blog/assets/js/62.6f6c77db.js"><link rel="prefetch" href="/blog/assets/js/63.fd62d822.js"><link rel="prefetch" href="/blog/assets/js/64.d83a9500.js"><link rel="prefetch" href="/blog/assets/js/65.e76b3053.js"><link rel="prefetch" href="/blog/assets/js/66.de39f9b4.js"><link rel="prefetch" href="/blog/assets/js/67.44ce2347.js"><link rel="prefetch" href="/blog/assets/js/68.9efe46cd.js"><link rel="prefetch" href="/blog/assets/js/69.a06475fc.js"><link rel="prefetch" href="/blog/assets/js/7.3df43e48.js"><link rel="prefetch" href="/blog/assets/js/70.d38d05d7.js"><link rel="prefetch" href="/blog/assets/js/71.563b0c4a.js"><link rel="prefetch" href="/blog/assets/js/72.14bc1390.js"><link rel="prefetch" href="/blog/assets/js/73.9d176c78.js"><link rel="prefetch" href="/blog/assets/js/74.3a37688f.js"><link rel="prefetch" href="/blog/assets/js/75.7c4802f6.js"><link rel="prefetch" href="/blog/assets/js/76.7309aafa.js"><link rel="prefetch" href="/blog/assets/js/77.418b1686.js"><link rel="prefetch" href="/blog/assets/js/78.8b748ecf.js"><link rel="prefetch" href="/blog/assets/js/8.417a4fef.js"><link rel="prefetch" href="/blog/assets/js/9.28024d7d.js">
    <link rel="stylesheet" href="/blog/assets/css/0.styles.c74f429a.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container" data-v-1c636796><div data-v-1c636796><div class="password-shadow password-wrapper-out" style="display:none;" data-v-2c3e9f55 data-v-1c636796 data-v-1c636796><h3 class="title" data-v-2c3e9f55>Adopat的博客</h3> <p class="description" data-v-2c3e9f55>长路漫漫，唯键作伴</p> <label id="box" class="inputBox" data-v-2c3e9f55><input type="password" value="" data-v-2c3e9f55> <span data-v-2c3e9f55>Konck! Knock!</span> <button data-v-2c3e9f55>OK</button></label> <div class="footer" data-v-2c3e9f55><span data-v-2c3e9f55><i class="iconfont reco-theme" data-v-2c3e9f55></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-2c3e9f55>vuePress-theme-reco</a></span> <span data-v-2c3e9f55><i class="iconfont reco-copyright" data-v-2c3e9f55></i> <a data-v-2c3e9f55><span data-v-2c3e9f55>Adopat</span>
          
        <!---->
        2023
      </a></span></div></div> <div class="hide" data-v-1c636796><header class="navbar" data-v-1c636796><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/blog/" class="home-link router-link-active"><img src="/blog/logo.jpeg" alt="Adopat的博客" class="logo"> <span class="site-name">Adopat的博客</span></a> <div class="links"><div class="color-picker"><a class="color-button"><i class="iconfont reco-color"></i></a> <div class="color-picker-menu" style="display:none;"><div class="mode-options"><h4 class="title">Choose mode</h4> <ul class="color-mode-options"><li class="dark">dark</li><li class="auto active">auto</li><li class="light">light</li></ul></div></div></div> <div class="search-box"><i class="iconfont reco-search"></i> <input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/blog/" class="nav-link"><i class="iconfont reco-home"></i>
  HOME
</a></div><div class="nav-item"><a href="/blog/handbook/about/" class="nav-link"><i class="iconfont reco-document"></i>
  导读
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-category"></i>
      分类
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/blog/handbook/basic/composition-principle.html" class="nav-link"><i class="fa fa-solid fa-computer"></i>
  计算机基础
</a></li><li class="dropdown-item"><!----> <a href="/blog/handbook/frontend/basic.html" class="nav-link"><i class="fa fa-brands fa-js"></i>
  前端
</a></li><li class="dropdown-item"><!----> <a href="/blog/handbook/backend/java-core-basic.html" class="nav-link"><i class="fa fa-brands fa-java"></i>
  后端
</a></li><li class="dropdown-item"><!----> <a href="/blog/handbook/database/" class="nav-link"><i class="fa fa-solid fa-database"></i>
  数据库
</a></li><li class="dropdown-item"><!----> <a href="/blog/handbook/bigdata/hadoop.html" class="nav-link"><i class="fa fa-brands fa-hive"></i>
  大数据
</a></li><li class="dropdown-item"><!----> <a href="/blog/handbook/ml/python-core.html" class="nav-link"><i class="fa fa-brands fa-python"></i>
  人工智能
</a></li><li class="dropdown-item"><!----> <a href="/blog/handbook/devops/docker.html" class="nav-link"><i class="fa fa-brands fa-docker"></i>
  运维
</a></li><li class="dropdown-item"><!----> <a href="/blog/handbook/tools/Git.html" class="nav-link"><i class="fa fa-solid fa-toolbox"></i>
  常用开发工具
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-document"></i>
      友情链接
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://blog.csdn.net/weixin_44446122?type=blog" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="iconfont reco-csdn"></i>
  CSDN
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://github.com/Adopat" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="iconfont reco-github"></i>
  Github
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div> <!----></nav></div></header> <div class="sidebar-mask" data-v-1c636796></div> <aside class="sidebar" data-v-1c636796><div class="personal-info-wrapper" data-v-6f92ba70 data-v-1c636796><!----> <h3 class="name" data-v-6f92ba70>
    Adopat
  </h3> <div class="num" data-v-6f92ba70><div data-v-6f92ba70><h3 data-v-6f92ba70>67</h3> <h6 data-v-6f92ba70>文章</h6></div> <div data-v-6f92ba70><h3 data-v-6f92ba70>0</h3> <h6 data-v-6f92ba70>标签</h6></div></div> <ul class="social-links" data-v-6f92ba70></ul> <hr data-v-6f92ba70></div> <nav class="nav-links"><div class="nav-item"><a href="/blog/" class="nav-link"><i class="iconfont reco-home"></i>
  HOME
</a></div><div class="nav-item"><a href="/blog/handbook/about/" class="nav-link"><i class="iconfont reco-document"></i>
  导读
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-category"></i>
      分类
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/blog/handbook/basic/composition-principle.html" class="nav-link"><i class="fa fa-solid fa-computer"></i>
  计算机基础
</a></li><li class="dropdown-item"><!----> <a href="/blog/handbook/frontend/basic.html" class="nav-link"><i class="fa fa-brands fa-js"></i>
  前端
</a></li><li class="dropdown-item"><!----> <a href="/blog/handbook/backend/java-core-basic.html" class="nav-link"><i class="fa fa-brands fa-java"></i>
  后端
</a></li><li class="dropdown-item"><!----> <a href="/blog/handbook/database/" class="nav-link"><i class="fa fa-solid fa-database"></i>
  数据库
</a></li><li class="dropdown-item"><!----> <a href="/blog/handbook/bigdata/hadoop.html" class="nav-link"><i class="fa fa-brands fa-hive"></i>
  大数据
</a></li><li class="dropdown-item"><!----> <a href="/blog/handbook/ml/python-core.html" class="nav-link"><i class="fa fa-brands fa-python"></i>
  人工智能
</a></li><li class="dropdown-item"><!----> <a href="/blog/handbook/devops/docker.html" class="nav-link"><i class="fa fa-brands fa-docker"></i>
  运维
</a></li><li class="dropdown-item"><!----> <a href="/blog/handbook/tools/Git.html" class="nav-link"><i class="fa fa-solid fa-toolbox"></i>
  常用开发工具
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-document"></i>
      友情链接
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://blog.csdn.net/weixin_44446122?type=blog" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="iconfont reco-csdn"></i>
  CSDN
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://github.com/Adopat" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="iconfont reco-github"></i>
  Github
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div> <!----></nav> <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>大数据基础</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/blog/handbook/bigdata/hadoop.html" class="sidebar-link">第一章 Hadoop</a></li><li><a href="/blog/handbook/bigdata/hdfs.html" aria-current="page" class="active sidebar-link">第二章 HDFS</a></li><li><a href="/blog/handbook/bigdata/mapreduce.html" class="sidebar-link">第三章 MapReduce</a></li><li><a href="/blog/handbook/bigdata/mapreduce1.html" class="sidebar-link">第四章 MapReduce性能优化</a></li><li><a href="/blog/handbook/bigdata/yarn.html" class="sidebar-link">第五章 YARN</a></li><li><a href="/blog/handbook/bigdata/flume.html" class="sidebar-link">第六章 Flume</a></li><li><a href="/blog/handbook/bigdata/hive.html" class="sidebar-link">第七章 HIVE</a></li><li><a href="/blog/handbook/bigdata/scala.html" class="sidebar-link">第八章 Scala</a></li><li><a href="/blog/handbook/bigdata/spark.html" class="sidebar-link">第九章 Spark</a></li><li><a href="/blog/handbook/bigdata/flink.html" class="sidebar-link">第十章 Flink</a></li></ul></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>大数据进阶</span> <span class="arrow right"></span></p> <!----></section></li></ul> </aside> <div class="password-shadow password-wrapper-in" style="display:none;" data-v-2c3e9f55 data-v-1c636796><h3 class="title" data-v-2c3e9f55></h3> <!----> <label id="box" class="inputBox" data-v-2c3e9f55><input type="password" value="" data-v-2c3e9f55> <span data-v-2c3e9f55>Konck! Knock!</span> <button data-v-2c3e9f55>OK</button></label> <div class="footer" data-v-2c3e9f55><span data-v-2c3e9f55><i class="iconfont reco-theme" data-v-2c3e9f55></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-2c3e9f55>vuePress-theme-reco</a></span> <span data-v-2c3e9f55><i class="iconfont reco-copyright" data-v-2c3e9f55></i> <a data-v-2c3e9f55><span data-v-2c3e9f55>Adopat</span>
          
        <!---->
        2023
      </a></span></div></div> <div data-v-1c636796><div data-v-1c636796><main class="page"><section style="display:;"><div class="page-title"><h1 class="title">第二章 HDFS</h1> <div data-v-6acedb3b><i class="iconfont reco-account" data-v-6acedb3b><span data-v-6acedb3b>Adopat</span></i> <!----> <!----> <!----></div></div> <div class="theme-reco-content content__default"><h1 id="第二章-hdfs"><a href="#第二章-hdfs" class="header-anchor">#</a> 第二章 HDFS</h1> <h2 id="_2-1-hdfs-介绍"><a href="#_2-1-hdfs-介绍" class="header-anchor">#</a> 2.1 HDFS 介绍</h2> <ul><li><p>分布式文件系统设计思想</p> <p>用户请求查看数据时会请求主节点，主节点上面会存储维护着所有数据的存储信息，然后用户根据数据所在的节点信息去对应的节点去读取数据，这样压力就进行了分流。</p></li> <li><p>常见的分布式文件系统</p> <ul><li>GFS(谷歌)</li> <li>TFS(淘宝)</li> <li>S3(S3)</li></ul></li> <li><p>HDFS 定义</p> <p>HDFS的全称是Hadoop Distributed File System ，Hadoop的 分布式 文件系统,它是一种允许文件通过网络在多台主机上分享的文件系统，可以让多台机器上的多个用户分享文件和存储空间。</p></li></ul> <h2 id="_2-2-hdfs-基础操作"><a href="#_2-2-hdfs-基础操作" class="header-anchor">#</a> 2.2 HDFS 基础操作</h2> <ul><li><p>HDFS shell 格式</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code>bin/hdfs dfs <span class="token parameter variable">-xxx</span> scheme://authority/path
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><blockquote><p>xxx 指具体的命令 ,绝大多数命令和Linux 命令相同 scheme:hdfs quthority:ip:port ，<code>scheme://authority/</code>这个可以省略不写 因为hdfs在执行的时候会根据HDOOP_HOME自动识别配置文件中的fs.defaultFS属性</p></blockquote></li> <li><p>HDFS 常用操作</p> <ul><li><code>hdfs dfs -ls /</code>查询指定路径信息</li> <li><code>hdfs dfs -put xxx /</code>从本地上传文件</li> <li><code>hdfs dfs -cat /xxx</code>查看HDFS文件内容</li> <li><code>hdfs dfs -get /xxx</code>下载文件到本地</li> <li><code>hdfs dfs -mkdir -p</code>创建文件夹</li> <li><code>hdfs dfs -rm -r</code>删除文件夹</li></ul> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token comment"># 查询根目录下的文件</span>
<span class="token punctuation">[</span>root@bigdata01 hadoop-3.2.0<span class="token punctuation">]</span><span class="token comment"># hdfs dfs -ls /</span>
Found <span class="token number">4</span> items
-rw-r--r--   <span class="token number">2</span> root    supergroup       <span class="token number">1361</span> <span class="token number">2022</span>-01-05 <span class="token number">16</span>:05 /README.txt
drwxr-xr-x   - root    supergroup          <span class="token number">0</span> <span class="token number">2022</span>-01-05 <span class="token number">16</span>:08 /abc
drwxr-xr-x   - root    supergroup          <span class="token number">0</span> <span class="token number">2022</span>-01-06 <span class="token number">16</span>:01 /test
-rw-r--r--   <span class="token number">3</span> Adopat supergroup  <span class="token number">305555522</span> <span class="token number">2022</span>-01-06 <span class="token number">15</span>:46 /user.txt
You have new mail <span class="token keyword">in</span> /var/spool/mail/root
<span class="token comment"># 创建文件夹</span>
<span class="token punctuation">[</span>root@bigdata01 hadoop-3.2.0<span class="token punctuation">]</span><span class="token comment"># hdfs dfs -mkdir -p /666/777</span>
You have new mail <span class="token keyword">in</span> /var/spool/mail/root
<span class="token comment"># 递归显示所有目录的信息，可以在ls后面添加R参数</span>
<span class="token punctuation">[</span>root@bigdata01 hadoop-3.2.0<span class="token punctuation">]</span><span class="token comment"># hdfs dfs -ls -R /</span>
drwxr-xr-x   - root    supergroup          <span class="token number">0</span> <span class="token number">2022</span>-01-07 <span class="token number">15</span>:43 /666
drwxr-xr-x   - root    supergroup          <span class="token number">0</span> <span class="token number">2022</span>-01-07 <span class="token number">15</span>:43 /666/777
-rw-r--r--   <span class="token number">2</span> root    supergroup       <span class="token number">1361</span> <span class="token number">2022</span>-01-05 <span class="token number">16</span>:05 /README.txt
drwxr-xr-x   - root    supergroup          <span class="token number">0</span> <span class="token number">2022</span>-01-05 <span class="token number">16</span>:08 /abc
drwxr-xr-x   - root    supergroup          <span class="token number">0</span> <span class="token number">2022</span>-01-05 <span class="token number">16</span>:08 /abc/xyz
drwxr-xr-x   - root    supergroup          <span class="token number">0</span> <span class="token number">2022</span>-01-06 <span class="token number">16</span>:01 /test
-rw-r--r--   <span class="token number">3</span> Adopat supergroup  <span class="token number">305555522</span> <span class="token number">2022</span>-01-06 <span class="token number">15</span>:46 /user.txt
<span class="token punctuation">[</span>root@bigdata01 hadoop-3.2.0<span class="token punctuation">]</span><span class="token comment"># ll</span>
total <span class="token number">188</span>
drwxr-xr-x. <span class="token number">2</span> <span class="token number">1001</span> <span class="token number">1002</span>    <span class="token number">203</span> Jan  <span class="token number">8</span>  <span class="token number">2019</span> bin
drwxr-xr-x. <span class="token number">3</span> <span class="token number">1001</span> <span class="token number">1002</span>     <span class="token number">20</span> Jan  <span class="token number">5</span> <span class="token number">15</span>:17 etc
drwxr-xr-x. <span class="token number">2</span> <span class="token number">1001</span> <span class="token number">1002</span>    <span class="token number">106</span> Jan  <span class="token number">8</span>  <span class="token number">2019</span> include
drwxr-xr-x. <span class="token number">3</span> <span class="token number">1001</span> <span class="token number">1002</span>     <span class="token number">20</span> Jan  <span class="token number">8</span>  <span class="token number">2019</span> lib
drwxr-xr-x. <span class="token number">4</span> <span class="token number">1001</span> <span class="token number">1002</span>   <span class="token number">4096</span> Jan  <span class="token number">8</span>  <span class="token number">2019</span> libexec
-rw-rw-r--. <span class="token number">1</span> <span class="token number">1001</span> <span class="token number">1002</span> <span class="token number">150569</span> Oct <span class="token number">19</span>  <span class="token number">2018</span> LICENSE.txt
-rw-rw-r--. <span class="token number">1</span> <span class="token number">1001</span> <span class="token number">1002</span>  <span class="token number">22125</span> Oct <span class="token number">19</span>  <span class="token number">2018</span> NOTICE.txt
-rw-rw-r--. <span class="token number">1</span> <span class="token number">1001</span> <span class="token number">1002</span>   <span class="token number">1361</span> Oct <span class="token number">19</span>  <span class="token number">2018</span> README.txt
-rw-r--r--. <span class="token number">1</span> root root   <span class="token number">1361</span> Jan  <span class="token number">5</span> <span class="token number">16</span>:07 README.txt.bak
drwxr-xr-x. <span class="token number">3</span> <span class="token number">1001</span> <span class="token number">1002</span>   <span class="token number">4096</span> Jan  <span class="token number">5</span> <span class="token number">15</span>:07 sbin
drwxr-xr-x. <span class="token number">4</span> <span class="token number">1001</span> <span class="token number">1002</span>     <span class="token number">31</span> Jan  <span class="token number">8</span>  <span class="token number">2019</span> share
<span class="token comment"># 上传文件 到hdf</span>
<span class="token punctuation">[</span>root@bigdata01 hadoop-3.2.0<span class="token punctuation">]</span><span class="token comment"># hdfs dfs -put README.txt.bak /</span>
You have new mail <span class="token keyword">in</span> /var/spool/mail/root
<span class="token comment"># 递归查询文件，可以显示子目录</span>
<span class="token punctuation">[</span>root@bigdata01 hadoop-3.2.0<span class="token punctuation">]</span><span class="token comment"># hdfs dfs -ls -R /</span>
drwxr-xr-x   - root    supergroup          <span class="token number">0</span> <span class="token number">2022</span>-01-07 <span class="token number">15</span>:43 /666
drwxr-xr-x   - root    supergroup          <span class="token number">0</span> <span class="token number">2022</span>-01-07 <span class="token number">15</span>:43 /666/777
-rw-r--r--   <span class="token number">2</span> root    supergroup       <span class="token number">1361</span> <span class="token number">2022</span>-01-05 <span class="token number">16</span>:05 /README.txt
-rw-r--r--   <span class="token number">2</span> root    supergroup       <span class="token number">1361</span> <span class="token number">2022</span>-01-07 <span class="token number">15</span>:44 /README.txt.bak
drwxr-xr-x   - root    supergroup          <span class="token number">0</span> <span class="token number">2022</span>-01-05 <span class="token number">16</span>:08 /abc
drwxr-xr-x   - root    supergroup          <span class="token number">0</span> <span class="token number">2022</span>-01-05 <span class="token number">16</span>:08 /abc/xyz
drwxr-xr-x   - root    supergroup          <span class="token number">0</span> <span class="token number">2022</span>-01-06 <span class="token number">16</span>:01 /test
-rw-r--r--   <span class="token number">3</span> Adopat supergroup  <span class="token number">305555522</span> <span class="token number">2022</span>-01-06 <span class="token number">15</span>:46 /user.txt
<span class="token punctuation">[</span>root@bigdata01 hadoop-3.2.0<span class="token punctuation">]</span><span class="token comment"># hdfs dfs -ls / |grep /|wc -l</span>
<span class="token number">6</span>
You have new mail <span class="token keyword">in</span> /var/spool/mail/root
<span class="token punctuation">[</span>root@bigdata01 hadoop-3.2.0<span class="token punctuation">]</span><span class="token comment"># hdfs dfs -ls /</span>
Found <span class="token number">6</span> items
drwxr-xr-x   - root    supergroup          <span class="token number">0</span> <span class="token number">2022</span>-01-07 <span class="token number">15</span>:43 /666
-rw-r--r--   <span class="token number">2</span> root    supergroup       <span class="token number">1361</span> <span class="token number">2022</span>-01-05 <span class="token number">16</span>:05 /README.txt
-rw-r--r--   <span class="token number">2</span> root    supergroup       <span class="token number">1361</span> <span class="token number">2022</span>-01-07 <span class="token number">15</span>:44 /README.txt.bak
drwxr-xr-x   - root    supergroup          <span class="token number">0</span> <span class="token number">2022</span>-01-05 <span class="token number">16</span>:08 /abc
drwxr-xr-x   - root    supergroup          <span class="token number">0</span> <span class="token number">2022</span>-01-06 <span class="token number">16</span>:01 /test
-rw-r--r--   <span class="token number">3</span> Adopat supergroup  <span class="token number">305555522</span> <span class="token number">2022</span>-01-06 <span class="token number">15</span>:46 /user.txt
<span class="token comment"># 统计根目录下文件个数</span>
<span class="token punctuation">[</span>root@bigdata01 hadoop-3.2.0<span class="token punctuation">]</span><span class="token comment"># hdfs dfs -ls /|grep /|wc -l</span>
<span class="token number">6</span>
<span class="token punctuation">[</span>root@bigdata01 hadoop-3.2.0<span class="token punctuation">]</span><span class="token comment"># hdfs dfs -ls -R /|grep /|wc -l</span>
<span class="token number">8</span>
You have new mail <span class="token keyword">in</span> /var/spool/mail/root
<span class="token punctuation">[</span>root@bigdata01 hadoop-3.2.0<span class="token punctuation">]</span><span class="token comment"># hdfs dfs -ls /</span>
Found <span class="token number">6</span> items
drwxr-xr-x   - root    supergroup          <span class="token number">0</span> <span class="token number">2022</span>-01-07 <span class="token number">15</span>:43 /666
-rw-r--r--   <span class="token number">2</span> root    supergroup       <span class="token number">1361</span> <span class="token number">2022</span>-01-05 <span class="token number">16</span>:05 /README.txt
-rw-r--r--   <span class="token number">2</span> root    supergroup       <span class="token number">1361</span> <span class="token number">2022</span>-01-07 <span class="token number">15</span>:44 /README.txt.bak
drwxr-xr-x   - root    supergroup          <span class="token number">0</span> <span class="token number">2022</span>-01-05 <span class="token number">16</span>:08 /abc
drwxr-xr-x   - root    supergroup          <span class="token number">0</span> <span class="token number">2022</span>-01-06 <span class="token number">16</span>:01 /test
-rw-r--r--   <span class="token number">3</span> Adopat supergroup  <span class="token number">305555522</span> <span class="token number">2022</span>-01-06 <span class="token number">15</span>:46 /user.txt
You have new mail <span class="token keyword">in</span> /var/spool/mail/root
<span class="token comment"># 删除文件夹</span>
<span class="token punctuation">[</span>root@bigdata01 hadoop-3.2.0<span class="token punctuation">]</span><span class="token comment"># hdfs dfs -rm -r /666</span>
Deleted /666
<span class="token punctuation">[</span>root@bigdata01 hadoop-3.2.0<span class="token punctuation">]</span><span class="token comment"># hdfs dfs -ls /      </span>
Found <span class="token number">5</span> items
-rw-r--r--   <span class="token number">2</span> root    supergroup       <span class="token number">1361</span> <span class="token number">2022</span>-01-05 <span class="token number">16</span>:05 /README.txt
-rw-r--r--   <span class="token number">2</span> root    supergroup       <span class="token number">1361</span> <span class="token number">2022</span>-01-07 <span class="token number">15</span>:44 /README.txt.bak
drwxr-xr-x   - root    supergroup          <span class="token number">0</span> <span class="token number">2022</span>-01-05 <span class="token number">16</span>:08 /abc
drwxr-xr-x   - root    supergroup          <span class="token number">0</span> <span class="token number">2022</span>-01-06 <span class="token number">16</span>:01 /test
-rw-r--r--   <span class="token number">3</span> Adopat supergroup  <span class="token number">305555522</span> <span class="token number">2022</span>-01-06 <span class="token number">15</span>:46 /user.txt
<span class="token comment"># 下载文件</span>
<span class="token punctuation">[</span>root@bigdata01 hadoop-3.2.0<span class="token punctuation">]</span><span class="token comment"># hdfs dfs -get /README.txt.bak README.txt.bak666</span>
You have new mail <span class="token keyword">in</span> /var/spool/mail/root
<span class="token punctuation">[</span>root@bigdata01 hadoop-3.2.0<span class="token punctuation">]</span><span class="token comment"># ll</span>
total <span class="token number">192</span>
drwxr-xr-x. <span class="token number">2</span> <span class="token number">1001</span> <span class="token number">1002</span>    <span class="token number">203</span> Jan  <span class="token number">8</span>  <span class="token number">2019</span> bin
drwxr-xr-x. <span class="token number">3</span> <span class="token number">1001</span> <span class="token number">1002</span>     <span class="token number">20</span> Jan  <span class="token number">5</span> <span class="token number">15</span>:17 etc
drwxr-xr-x. <span class="token number">2</span> <span class="token number">1001</span> <span class="token number">1002</span>    <span class="token number">106</span> Jan  <span class="token number">8</span>  <span class="token number">2019</span> include
drwxr-xr-x. <span class="token number">3</span> <span class="token number">1001</span> <span class="token number">1002</span>     <span class="token number">20</span> Jan  <span class="token number">8</span>  <span class="token number">2019</span> lib
drwxr-xr-x. <span class="token number">4</span> <span class="token number">1001</span> <span class="token number">1002</span>   <span class="token number">4096</span> Jan  <span class="token number">8</span>  <span class="token number">2019</span> libexec
-rw-rw-r--. <span class="token number">1</span> <span class="token number">1001</span> <span class="token number">1002</span> <span class="token number">150569</span> Oct <span class="token number">19</span>  <span class="token number">2018</span> LICENSE.txt
-rw-rw-r--. <span class="token number">1</span> <span class="token number">1001</span> <span class="token number">1002</span>  <span class="token number">22125</span> Oct <span class="token number">19</span>  <span class="token number">2018</span> NOTICE.txt
-rw-rw-r--. <span class="token number">1</span> <span class="token number">1001</span> <span class="token number">1002</span>   <span class="token number">1361</span> Oct <span class="token number">19</span>  <span class="token number">2018</span> README.txt
-rw-r--r--. <span class="token number">1</span> root root   <span class="token number">1361</span> Jan  <span class="token number">5</span> <span class="token number">16</span>:07 README.txt.bak
-rw-r--r--. <span class="token number">1</span> root root   <span class="token number">1361</span> Jan  <span class="token number">7</span> <span class="token number">16</span>:02 README.txt.bak666
drwxr-xr-x. <span class="token number">3</span> <span class="token number">1001</span> <span class="token number">1002</span>   <span class="token number">4096</span> Jan  <span class="token number">5</span> <span class="token number">15</span>:07 sbin
drwxr-xr-x. <span class="token number">4</span> <span class="token number">1001</span> <span class="token number">1002</span>     <span class="token number">31</span> Jan  <span class="token number">8</span>  <span class="token number">2019</span> share
<span class="token punctuation">[</span>root@bigdata01 hadoop-3.2.0<span class="token punctuation">]</span><span class="token comment"># hdfs dfs -ls /README.txt</span>
-rw-r--r--   <span class="token number">2</span> root supergroup       <span class="token number">1361</span> <span class="token number">2022</span>-01-05 <span class="token number">16</span>:05 /README.txt
<span class="token punctuation">[</span>root@bigdata01 hadoop-3.2.0<span class="token punctuation">]</span><span class="token comment"># hdfs dfs -cat /README.txt</span>
For the latest information about Hadoop, please visit our website at:
<span class="token punctuation">..</span>.
<span class="token punctuation">[</span>root@bigdata01 hadoop-3.2.0<span class="token punctuation">]</span><span class="token comment"># </span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br><span class="line-number">50</span><br><span class="line-number">51</span><br><span class="line-number">52</span><br><span class="line-number">53</span><br><span class="line-number">54</span><br><span class="line-number">55</span><br><span class="line-number">56</span><br><span class="line-number">57</span><br><span class="line-number">58</span><br><span class="line-number">59</span><br><span class="line-number">60</span><br><span class="line-number">61</span><br><span class="line-number">62</span><br><span class="line-number">63</span><br><span class="line-number">64</span><br><span class="line-number">65</span><br><span class="line-number">66</span><br><span class="line-number">67</span><br><span class="line-number">68</span><br><span class="line-number">69</span><br><span class="line-number">70</span><br><span class="line-number">71</span><br><span class="line-number">72</span><br><span class="line-number">73</span><br><span class="line-number">74</span><br><span class="line-number">75</span><br><span class="line-number">76</span><br><span class="line-number">77</span><br><span class="line-number">78</span><br><span class="line-number">79</span><br><span class="line-number">80</span><br><span class="line-number">81</span><br><span class="line-number">82</span><br><span class="line-number">83</span><br><span class="line-number">84</span><br><span class="line-number">85</span><br><span class="line-number">86</span><br><span class="line-number">87</span><br><span class="line-number">88</span><br><span class="line-number">89</span><br><span class="line-number">90</span><br><span class="line-number">91</span><br><span class="line-number">92</span><br><span class="line-number">93</span><br><span class="line-number">94</span><br><span class="line-number">95</span><br><span class="line-number">96</span><br><span class="line-number">97</span><br><span class="line-number">98</span><br><span class="line-number">99</span><br><span class="line-number">100</span><br><span class="line-number">101</span><br><span class="line-number">102</span><br><span class="line-number">103</span><br><span class="line-number">104</span><br><span class="line-number">105</span><br></div></div></li></ul> <h2 id="_2-3-java操作hdfs"><a href="#_2-3-java操作hdfs" class="header-anchor">#</a> 2.3 Java操作HDFS</h2> <p>代码详见github https://github.com/Adopat/hadoop_demo</p> <h2 id="_2-4-hdfs核心进程"><a href="#_2-4-hdfs核心进程" class="header-anchor">#</a> 2.4 HDFS核心进程</h2> <p>HDFS 核心进程分三个</p> <ul><li>NameNode</li> <li>SecondaryNameNode</li> <li>DataNode</li></ul> <h3 id="_2-4-1-namenode"><a href="#_2-4-1-namenode" class="header-anchor">#</a> 2.4.1 NameNode</h3> <p>NameNode是整个文件系统的管理节点，主要功能有以下三个</p> <ol><li><p>维护整个文件系统的文件目录树</p> <blockquote><p>表示文件/目录的的一些基本信息，所有者 属组 修改时间 文件大小等信息)</p></blockquote></li> <li><p>维护每个文件对应的数据块列表</p> <blockquote><p>如果一个文件太大，那么在集群中存储的时候会对文件进行切割，这个时候就类似于会给文件分成一块一块的，存储到不同机器上面。所以HDFS还要记录一下一个文件到底被分了多少块，每一块都在什么地方存储着</p></blockquote></li> <li><p>负责接收用户的操作请求</p> <blockquote><p>我们在命令行使用hdfs的时候，需要先和namenode通信才能开始去操作数据)</p></blockquote></li></ol> <p>NameNode主要包含以下文件</p> <ol><li><p>fsimage</p> <p>元数据镜像文件，存储某一时刻NameNode内存中的元数据信息，就类似是定时做了一个快照操作。【这里的元数据信息是指文件目录树、文件/目录的信息、每个文件对应的数据块列表】</p></li> <li><p>edits</p> <p>操作日志文件【事务文件】，这里面会实时记录用户的所有操作。,我们所有对hdfs的增删改操作都会在edits文件中留下信息，edits文件会定期合并到fsimage文件中(SecondaryNameNode的作用)</p></li> <li><p>seen_txid</p> <p>是存放transactionId的文件，format之后是0，它代表的是namenode里面的edits_*文件的尾数,namenode重启的时候，会按照seen_txid的数字，顺序从头跑edits_0000001~到seen_txid的数字。如果根据对应的seen_txid无法加载到对应的文件，NameNode进程将不会完成启动以保护数据一致性。</p></li> <li><p>VERSION</p> <p>保存了集群的版本信息，这里面显示的集群的一些信息、当重新对hdfs格式化 之后，这里面的信息会变化。</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token punctuation">[</span>root@bigdata01 current<span class="token punctuation">]</span><span class="token comment"># cat VERSION </span>
<span class="token comment">#Wed Apr 08 20:30:00 CST 2020 </span>
<span class="token assign-left variable">namespaceID</span><span class="token operator">=</span><span class="token number">498554338</span> 
<span class="token assign-left variable">clusterID</span><span class="token operator">=</span>CID-cc0792dd-a861-4a3f-9151-b0695e4c7e70 <span class="token assign-left variable">cTime</span><span class="token operator">=</span><span class="token number">1586268855170</span> <span class="token assign-left variable">storageType</span><span class="token operator">=</span>NAME_NODE 
<span class="token assign-left variable">blockpoolID</span><span class="token operator">=</span>BP-1517789416-192.168.35.100-1586268855170 
<span class="token assign-left variable">layoutVersion</span><span class="token operator">=</span>-65
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><blockquote><p>hdfs 格式化 会改变clusterID,导致和从节点不一致，所以不建议重复格式化，是在要格式化 删除 /data/hadoop_repo 也就是NameNode 文件的存放路径</p></blockquote></li></ol> <p>NameNode 存放目录</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token operator">&lt;</span>property<span class="token operator">&gt;</span>
  <span class="token operator">&lt;</span>name<span class="token operator">&gt;</span>dfs.namenode.name.dir<span class="token operator">&lt;</span>/name<span class="token operator">&gt;</span>
  <span class="token operator">&lt;</span>value<span class="token operator">&gt;</span>file://<span class="token variable">${hadoop.tmp.dir}</span>/dfs/name<span class="token operator">&lt;</span>/value<span class="token operator">&gt;</span>
  <span class="token operator">&lt;</span>description<span class="token operator">&gt;</span>Determines where on the <span class="token builtin class-name">local</span> filesystem the DFS name <span class="token function">node</span>
      should store the name table<span class="token punctuation">(</span>fsimage<span class="token punctuation">)</span>.  If this is a comma-delimited list
      of directories <span class="token keyword">then</span> the name table is replicated <span class="token keyword">in</span> all of the
      directories, <span class="token keyword">for</span> redundancy. <span class="token operator">&lt;</span>/description<span class="token operator">&gt;</span>
<span class="token operator">&lt;</span>/property<span class="token operator">&gt;</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><blockquote><p>默认 hdfs-default.xml(hadoop-3.2.0\share\hadoop\hdfs\hadoop-hdfs-3.2.0.jar) 属性中定义了namenode文件存放路径，但是我们在配置了core-site.xml 中重新定义了存放路径，对原始属性进行了覆盖</p></blockquote> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token punctuation">[</span>root@bigdata01 hadoop-3.2.0<span class="token punctuation">]</span><span class="token comment"># cat etc/hadoop/core-site.xml</span>
<span class="token operator">&lt;</span>configuration<span class="token operator">&gt;</span>
<span class="token operator">&lt;</span>property<span class="token operator">&gt;</span> 
    <span class="token operator">&lt;</span>name<span class="token operator">&gt;</span>fs.defaultFS<span class="token operator">&lt;</span>/name<span class="token operator">&gt;</span>
    <span class="token operator">&lt;</span>value<span class="token operator">&gt;</span>hdfs://bigdata01:900<span class="token operator"><span class="token file-descriptor important">0</span>&lt;</span>/value<span class="token operator">&gt;</span>
<span class="token operator">&lt;</span>/property<span class="token operator">&gt;</span>
<span class="token operator">&lt;</span>property<span class="token operator">&gt;</span> 
    <span class="token operator">&lt;</span>name<span class="token operator">&gt;</span>hadoop.tmp.dir<span class="token operator">&lt;</span>/name<span class="token operator">&gt;</span>
    <span class="token operator">&lt;</span>value<span class="token operator">&gt;</span>/data/hadoop_repo<span class="token operator">&lt;</span>/value<span class="token operator">&gt;</span>
<span class="token operator">&lt;</span>/property<span class="token operator">&gt;</span>
<span class="token operator">&lt;</span>/configuration<span class="token operator">&gt;</span>
You have new mail <span class="token keyword">in</span> /var/spool/mail/root
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br></div></div><blockquote><p>所以目前 nanenode的存放路径就是 /data/hadoop_repo/dfs/name</p></blockquote> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code>-rw-r--r--. <span class="token number">1</span> root root <span class="token number">1048576</span> Jan  <span class="token number">5</span> <span class="token number">15</span>:40 edits_0000000000000000001-0000000000000000001
-rw-r--r--. <span class="token number">1</span> root root     <span class="token number">748</span> Jan  <span class="token number">5</span> <span class="token number">16</span>:21 edits_0000000000000000002-0000000000000000012
-rw-r--r--. <span class="token number">1</span> root root      <span class="token number">42</span> Jan  <span class="token number">5</span> <span class="token number">17</span>:21 edits_0000000000000000013-0000000000000000014
-rw-r--r--. <span class="token number">1</span> root root      <span class="token number">42</span> Jan  <span class="token number">5</span> <span class="token number">18</span>:21 edits_0000000000000000015-0000000000000000016
-rw-r--r--. <span class="token number">1</span> root root <span class="token number">1048576</span> Jan  <span class="token number">5</span> <span class="token number">18</span>:21 edits_0000000000000000017-0000000000000000017
-rw-r--r--. <span class="token number">1</span> root root      <span class="token number">42</span> Jan  <span class="token number">6</span> <span class="token number">13</span>:14 edits_0000000000000000018-0000000000000000019
-rw-r--r--. <span class="token number">1</span> root root      <span class="token number">42</span> Jan  <span class="token number">6</span> <span class="token number">14</span>:14 edits_0000000000000000020-0000000000000000021
-rw-r--r--. <span class="token number">1</span> root root <span class="token number">1048576</span> Jan  <span class="token number">6</span> <span class="token number">14</span>:14 edits_0000000000000000022-0000000000000000022
-rw-r--r--. <span class="token number">1</span> root root      <span class="token number">42</span> Jan  <span class="token number">6</span> <span class="token number">15</span>:05 edits_0000000000000000023-0000000000000000024
-rw-r--r--. <span class="token number">1</span> root root    <span class="token number">4200</span> Jan  <span class="token number">6</span> <span class="token number">16</span>:05 edits_0000000000000000025-0000000000000000092
-rw-r--r--. <span class="token number">1</span> root root      <span class="token number">42</span> Jan  <span class="token number">6</span> <span class="token number">17</span>:05 edits_0000000000000000093-0000000000000000094
-rw-r--r--. <span class="token number">1</span> root root      <span class="token number">42</span> Jan  <span class="token number">6</span> <span class="token number">18</span>:05 edits_0000000000000000095-0000000000000000096
-rw-r--r--. <span class="token number">1</span> root root      <span class="token number">42</span> Jan  <span class="token number">6</span> <span class="token number">19</span>:05 edits_0000000000000000097-0000000000000000098
-rw-r--r--. <span class="token number">1</span> root root <span class="token number">1048576</span> Jan  <span class="token number">6</span> <span class="token number">19</span>:05 edits_0000000000000000099-0000000000000000099
-rw-r--r--. <span class="token number">1</span> root root      <span class="token number">42</span> Jan  <span class="token number">7</span> 09:46 edits_0000000000000000100-0000000000000000101
-rw-r--r--. <span class="token number">1</span> root root <span class="token number">1048576</span> Jan  <span class="token number">7</span> 09:46 edits_0000000000000000102-0000000000000000102
-rw-r--r--. <span class="token number">1</span> root root      <span class="token number">42</span> Jan  <span class="token number">7</span> <span class="token number">14</span>:16 edits_0000000000000000103-0000000000000000104
-rw-r--r--. <span class="token number">1</span> root root <span class="token number">1048576</span> Jan  <span class="token number">7</span> <span class="token number">14</span>:16 edits_0000000000000000105-0000000000000000105
-rw-r--r--. <span class="token number">1</span> root root      <span class="token number">42</span> Jan  <span class="token number">7</span> <span class="token number">15</span>:41 edits_0000000000000000106-0000000000000000107
-rw-r--r--. <span class="token number">1</span> root root     <span class="token number">796</span> Jan  <span class="token number">7</span> <span class="token number">16</span>:41 edits_0000000000000000108-0000000000000000119
-rw-r--r--. <span class="token number">1</span> root root      <span class="token number">42</span> Jan  <span class="token number">7</span> <span class="token number">17</span>:41 edits_0000000000000000120-0000000000000000121
-rw-r--r--. <span class="token number">1</span> root root <span class="token number">1048576</span> Jan  <span class="token number">7</span> <span class="token number">17</span>:41 edits_0000000000000000122-0000000000000000122
-rw-r--r--. <span class="token number">1</span> root root      <span class="token number">42</span> Jan  <span class="token number">8</span> <span class="token number">10</span>:22 edits_0000000000000000123-0000000000000000124
-rw-r--r--. <span class="token number">1</span> root root <span class="token number">1048576</span> Jan  <span class="token number">8</span> <span class="token number">10</span>:22 edits_inprogress_0000000000000000125
-rw-r--r--. <span class="token number">1</span> root root     <span class="token number">874</span> Jan  <span class="token number">8</span> <span class="token number">10</span>:21 fsimage_0000000000000000122
-rw-r--r--. <span class="token number">1</span> root root      <span class="token number">62</span> Jan  <span class="token number">8</span> <span class="token number">10</span>:21 fsimage_0000000000000000122.md5
-rw-r--r--. <span class="token number">1</span> root root     <span class="token number">874</span> Jan  <span class="token number">8</span> <span class="token number">10</span>:22 fsimage_0000000000000000124
-rw-r--r--. <span class="token number">1</span> root root      <span class="token number">62</span> Jan  <span class="token number">8</span> <span class="token number">10</span>:22 fsimage_0000000000000000124.md5
-rw-r--r--. <span class="token number">1</span> root root       <span class="token number">4</span> Jan  <span class="token number">8</span> <span class="token number">10</span>:22 seen_txid
-rw-r--r--. <span class="token number">1</span> root root     <span class="token number">219</span> Jan  <span class="token number">8</span> <span class="token number">10</span>:21 VERSION
<span class="token punctuation">[</span>root@bigdata01 current<span class="token punctuation">]</span><span class="token comment"># pwd</span>
/data/hadoop_repo/dfs/name/current
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br></div></div><blockquote><p>namenode 文件存放路径，fsimage 文件解析https://blog.csdn.net/baidu_31618421/article/details/107218846</p></blockquote> <h3 id="_2-4-2-secondarynamenode"><a href="#_2-4-2-secondarynamenode" class="header-anchor">#</a> 2.4.2 SecondaryNameNode</h3> <p>SecondaryNameNode 的主要功能是负责定期把edits 文件中的内容合并到fsimage中这个合并操作称为checkpoint，在合并的时候会对edits中的内容进行转换，生成新的内容保存到fsimage文件中。</p> <blockquote><p>注意：在NameNode的HA(High Avariable)架构中没有SecondaryNameNode进程，文件合并操作会由standbyNameNode负责实现
所以在Hadoop集群中，SecondaryNameNode进程并不是必须的。</p></blockquote> <h3 id="_2-4-3-datanode"><a href="#_2-4-3-datanode" class="header-anchor">#</a> 2.4.3 DataNode</h3> <p>DateNode是提供真实文件数据的存储服务。</p> <ul><li><p>block</p> <p>HDFS会按照固定的大小，顺序对文件进行划分并编号，划分好的每一个块称一个Block，<strong>HDFS默认Block大小是 128MB</strong>
Blokc块是HDFS读写数据的基本单位，不管你的文件是文本文件 还是视频 或者音频文件，针对hdfs而言都是字节。</p></li> <li><p>replication</p> <p>备份在hdfs-site.xml中进行配置(df.replication),默认这个参数的配置是3</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token comment"># hdfs-site.xml 中对dfs.replication 进行覆盖</span>
<span class="token operator">&lt;</span>configuration<span class="token operator">&gt;</span> 
    <span class="token operator">&lt;</span>property<span class="token operator">&gt;</span> 
        <span class="token operator">&lt;</span>name<span class="token operator">&gt;</span>dfs.replication<span class="token operator">&lt;</span>/name<span class="token operator">&gt;</span> 
        <span class="token operator">&lt;</span>value<span class="token operator">&gt;</span><span class="token operator"><span class="token file-descriptor important">2</span>&lt;</span>/value<span class="token operator">&gt;</span> 
    <span class="token operator">&lt;</span>/property<span class="token operator">&gt;</span> 
    <span class="token operator">&lt;</span>property<span class="token operator">&gt;</span> 
        <span class="token operator">&lt;</span>name<span class="token operator">&gt;</span>dfs.namenode.secondary.http-address<span class="token operator">&lt;</span>/name<span class="token operator">&gt;</span> 
        <span class="token operator">&lt;</span>value<span class="token operator">&gt;</span>bigdata01:5009<span class="token operator"><span class="token file-descriptor important">0</span>&lt;</span>/value<span class="token operator">&gt;</span> 
    <span class="token operator">&lt;</span>/property<span class="token operator">&gt;</span>
    <span class="token operator">&lt;</span>property<span class="token operator">&gt;</span>
        <span class="token operator">&lt;</span>name<span class="token operator">&gt;</span>dfs.permissions.enabled<span class="token operator">&lt;</span>/name<span class="token operator">&gt;</span>
        <span class="token operator">&lt;</span>value<span class="token operator">&gt;</span>false<span class="token operator">&lt;</span>/value<span class="token operator">&gt;</span> 
    <span class="token operator">&lt;</span>/property<span class="token operator">&gt;</span>
<span class="token operator">&lt;</span>/configuration<span class="token operator">&gt;</span>
<span class="token punctuation">[</span>root@bigdata01 hadoop<span class="token punctuation">]</span><span class="token comment"># pwd</span>
/data/soft/hadoop-3.2.0/etc/hadoop
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br></div></div><div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token comment"># 在 hdfs-default.xml 中默认是3</span>
<span class="token operator">&lt;</span>property<span class="token operator">&gt;</span>
  <span class="token operator">&lt;</span>name<span class="token operator">&gt;</span>dfs.replication<span class="token operator">&lt;</span>/name<span class="token operator">&gt;</span>
  <span class="token operator">&lt;</span>value<span class="token operator">&gt;</span><span class="token operator"><span class="token file-descriptor important">3</span>&lt;</span>/value<span class="token operator">&gt;</span>
  <span class="token operator">&lt;</span>description<span class="token operator">&gt;</span>Default block replication. 
  The actual number of replications can be specified when the <span class="token function">file</span> is created.
  The default is used <span class="token keyword">if</span> replication is not specified <span class="token keyword">in</span> create time.
  <span class="token operator">&lt;</span>/description<span class="token operator">&gt;</span>
<span class="token operator">&lt;</span>/property<span class="token operator">&gt;</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div></li></ul> <h3 id="_2-4-4-总结"><a href="#_2-4-4-总结" class="header-anchor">#</a> 2.4.4 总结</h3> <p>如何找到文件，用户请求数据，NameNode 接收用户请求，根据fsimage(edits)文件中保存的文件和block 块的信息，找到对应的block,通过block 找到对应的datanode.。datanode 存储了真正的数据信息。</p> <p>NameNode维护了两份关系：
第一份关系：file 与block list的关系，对应的关系信息存储在fsimage和edits文件中,当NameNode启动的时候会把文件中的元数据信息加载到内存中
第二份关系：datanode与block的关系，对应的关系主要在集群启动的时候保存在内存中,当DataNode启动时会把当前节点上的Block信息和节点信息上报给NameNode</p> <blockquote><p>HDFS不适合存储小文件，其实主要原因就在这里，不管是大文件还是小文件，一个文件的元数据信息在NameNode中都会占用150字节，NameNode节点的内存是有限的，所以它的存储能力也是有限的，如果我们存储了一堆都是几KB的小文件，最后发现NameNode的内存占满了，确实存储了很多文件，但是文件的总体大小却很小，这样就失去了HDFS存在的价值。</p></blockquote> <h2 id="_2-5hdfs-高级"><a href="#_2-5hdfs-高级" class="header-anchor">#</a> 2.5HDFS 高级</h2> <h3 id="_2-5-1-hdfs的回收站"><a href="#_2-5-1-hdfs的回收站" class="header-anchor">#</a> 2.5.1 HDFS的回收站</h3> <p>回收站的数据，有一个生存周期,默认HDFS的回收站是没有开启的。</p> <p><strong>HDFS回收站配置</strong></p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token comment"># 1.修改配置core-site.xml</span>
<span class="token punctuation">[</span>root@bigdata01 hadoop<span class="token punctuation">]</span><span class="token comment"># pwd</span>
/data/soft/hadoop-3.2.0/etc/hadoop
<span class="token punctuation">[</span>root@bigdata01 hadoop<span class="token punctuation">]</span><span class="token comment"># vi core-site.xml </span>
<span class="token operator">&lt;</span>configuration<span class="token operator">&gt;</span>
<span class="token operator">&lt;</span>property<span class="token operator">&gt;</span> 
    <span class="token operator">&lt;</span>name<span class="token operator">&gt;</span>fs.defaultFS<span class="token operator">&lt;</span>/name<span class="token operator">&gt;</span>
    <span class="token operator">&lt;</span>value<span class="token operator">&gt;</span>hdfs://bigdata01:900<span class="token operator"><span class="token file-descriptor important">0</span>&lt;</span>/value<span class="token operator">&gt;</span>
<span class="token operator">&lt;</span>/property<span class="token operator">&gt;</span>
<span class="token operator">&lt;</span>property<span class="token operator">&gt;</span> 
    <span class="token operator">&lt;</span>name<span class="token operator">&gt;</span>hadoop.tmp.dir<span class="token operator">&lt;</span>/name<span class="token operator">&gt;</span>
    <span class="token operator">&lt;</span>value<span class="token operator">&gt;</span>/data/hadoop_repo<span class="token operator">&lt;</span>/value<span class="token operator">&gt;</span>
<span class="token operator">&lt;</span>/property<span class="token operator">&gt;</span>
<span class="token comment"># 开启回收站 value单位是分钟 1440指的是回收站保存一天，超过时间自动删除</span>
<span class="token operator">&lt;</span>property<span class="token operator">&gt;</span> 
    <span class="token operator">&lt;</span>name<span class="token operator">&gt;</span>fs.trash.interval<span class="token operator">&lt;</span>/name<span class="token operator">&gt;</span>
    <span class="token operator">&lt;</span>value<span class="token operator">&gt;</span><span class="token number">144</span><span class="token operator"><span class="token file-descriptor important">0</span>&lt;</span>/value<span class="token operator">&gt;</span> 
<span class="token operator">&lt;</span>/property<span class="token operator">&gt;</span>
<span class="token operator">&lt;</span>/configuration<span class="token operator">&gt;</span>
<span class="token comment"># 2.将配置同步到剩余的节点信息</span>
<span class="token punctuation">[</span>root@bigdata01 hadoop<span class="token punctuation">]</span><span class="token comment"># pwd</span>
/data/soft/hadoop-3.2.0/etc/hadoop
<span class="token punctuation">[</span>root@bigdata01 hadoop<span class="token punctuation">]</span><span class="token comment"># scp -rq core-site.xml bigdata02:/data/soft/hadoop-3.2.0/etc/hadoop</span>
You have new mail <span class="token keyword">in</span> /var/spool/mail/root
<span class="token punctuation">[</span>root@bigdata01 hadoop<span class="token punctuation">]</span><span class="token comment"># scp -rq core-site.xml bigdata03:/data/soft/hadoop-3.2.0/etc/hadoop</span>
<span class="token comment"># 3.删除文件</span>
<span class="token punctuation">[</span>root@bigdata01 hadoop-3.2.0<span class="token punctuation">]</span><span class="token comment"># hdfs dfs -rm -r -f /README_DELETE.txt</span>
<span class="token number">2022</span>-01-10 09:20:42,084 INFO fs.TrashPolicyDefault: Moved: <span class="token string">'hdfs://bigdata01:9000/README_DELETE.txt'</span> to trash at: hdfs://bigdata01:9000/user/root/.Trash/Current/README_DELETE.txt1641777642074
You have new mail <span class="token keyword">in</span> /var/spool/mail/root
<span class="token comment"># 4.查看删除文件</span>
<span class="token punctuation">[</span>root@bigdata01 hadoop-3.2.0<span class="token punctuation">]</span><span class="token comment"># hdfs dfs -ls  /user/root/.Trash/Current/  </span>
Found <span class="token number">2</span> items
-rw-r--r--   <span class="token number">2</span> root supergroup       <span class="token number">1361</span> <span class="token number">2022</span>-01-10 09:15 /user/root/.Trash/Current/README_DELETE.txt
-rw-r--r--   <span class="token number">2</span> root supergroup       <span class="token number">1361</span> <span class="token number">2022</span>-01-10 09:17 /user/root/.Trash/Current/README_DELETE.txt1641777642074
You have new mail <span class="token keyword">in</span> /var/spool/mail/root
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br></div></div><blockquote><p>在修改配置之前，需要先停止集群，</p> <p>注意：如果删除的文件过大，超过回收站大小的话会提示删除失败
需要指定参数 -skipTrash ，指定这个参数表示删除的文件不会进回收站</p> <p><code>[root@bigdata01 hadoop-3.2.0]# hdfs dfs -rm -r -skipTrash /README.txt</code></p> <p><code>Deleted /user.txt</code></p></blockquote> <h3 id="_2-5-2-hdfs的安全模式"><a href="#_2-5-2-hdfs的安全模式" class="header-anchor">#</a> 2.5.2 HDFS的安全模式</h3> <p>集群刚启动的时候会进入一种无法上传或者删除文件的状态，这种状态称为HDFS的安全模式。，因为在集群每次重新启动的时候，HDFS都会检查集群中文件信息是否完整，例如副本是否缺少之类的信息，所以这个时间段内是不允许对集群有修改操作的。</p> <ul><li><p>查看是否安全模式</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token punctuation">[</span>root@bigdata01 hadoop-3.2.0<span class="token punctuation">]</span><span class="token comment"># hdfs dfsadmin -safemode get</span>
Safe mode is OFF
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div></li> <li><p>离开安全模式</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token punctuation">[</span>root@bigdata01 hadoop-3.2.0<span class="token punctuation">]</span><span class="token comment"># hdfs dfsadmin -safemode leave Safe mode is OFF</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div></li></ul> <h3 id="_2-5-3-实时上传数据至hdfs"><a href="#_2-5-3-实时上传数据至hdfs" class="header-anchor">#</a> 2.5.3 实时上传数据至HDFS</h3> <ul><li><p>需求</p> <p>在实际工作中会有定时上传数据到HDFS的需求，我们有一个web项目每天都会产生日志文件，日志文件的格式为access_2022_01_01.log这种格式的，每天产生一个，我们需要每天凌晨将昨天生成的日志文件上传至HDFS上，按天分目录存储，HDFS上的目录格式为20220101</p></li> <li><p>实现思路</p> <p>第一步：我们需要获取到昨天日志文件的名称
第二步：在HDFS上面使用昨天的日期创建目录
第三步：将昨天的日志文件上传到刚创建的HDFS目录中
第四步：要考虑到脚本重跑，补数据的情况
第五步：配置crontab任务</p></li> <li><p>实现代码</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token punctuation">[</span>root@bigdata01 shell<span class="token punctuation">]</span><span class="token comment"># cat uploadLogData.sh </span>
<span class="token comment">#!/bin/bash</span>
<span class="token comment"># 1.获取昨天日期字符串</span>
<span class="token comment"># 考虑到脚本重跑补数据情况</span>
<span class="token assign-left variable">yesterday</span><span class="token operator">=</span><span class="token variable">$1</span>
<span class="token keyword">if</span> <span class="token punctuation">[</span> <span class="token string">&quot;<span class="token variable">$yesterday</span>&quot;</span> <span class="token operator">=</span> <span class="token string">&quot;&quot;</span> <span class="token punctuation">]</span>
<span class="token keyword">then</span>
<span class="token assign-left variable">yesterday</span><span class="token operator">=</span><span class="token variable"><span class="token variable">`</span><span class="token function">date</span> +%Y_%m_%d <span class="token parameter variable">--date</span><span class="token operator">=</span><span class="token string">&quot;1 days ago&quot;</span><span class="token variable">`</span></span>
<span class="token keyword">fi</span>
<span class="token comment"># 拼接日志文件路径信息</span>
<span class="token assign-left variable">logPath</span><span class="token operator">=</span>/data/log/access_<span class="token variable">${yesterday}</span>.log
<span class="token comment"># 将日期中的_去除</span>
<span class="token assign-left variable">hdfsPath</span><span class="token operator">=</span>/log/<span class="token variable">${yesterday<span class="token operator">/</span><span class="token operator">/</span>_<span class="token operator">/</span>}</span>
<span class="token comment"># 在hdfs 中创建目录</span>
hdfs dfs <span class="token parameter variable">-mkdir</span> <span class="token parameter variable">-p</span> <span class="token variable">${hdfsPath}</span>
<span class="token comment"># 将数据上传至hdfs的指定目录中</span>
hdfs dfs <span class="token parameter variable">-put</span> <span class="token variable">${logPath}</span> <span class="token variable">${hdfsPath}</span>
<span class="token comment"># 配置crontabl 任务，每天凌晨1点执行</span>
<span class="token punctuation">[</span>root@bigdata01 shell<span class="token punctuation">]</span><span class="token comment"># </span>
<span class="token punctuation">[</span>root@bigdata01 shell<span class="token punctuation">]</span><span class="token comment"># vi /etc/crontab 0 1 * * * root sh /data/shell/uploadLogData.sh &gt;&gt; /data/shell/uploadLogData.log</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br></div></div></li></ul> <h3 id="_2-5-4-ha-高可用"><a href="#_2-5-4-ha-高可用" class="header-anchor">#</a> 2.5.4 HA 高可用</h3> <p>High Available，指的是NameNode 一主多备，在这里明确JN(JournalNodes集群用于同步edits信息(静态))，DateNode 需要向所有的NameNode 发送block 与节点信息(动态)，Zookeeper 集群可以用来自动切换ActiveNameNode。HA解决了NameNode 的单点故障问题。</p> <p><img src="/blog/Hadoop%E7%94%9F%E6%80%81%E4%BD%93%E7%B3%BB.assets/image-20220110151231521.png" alt="image-20220110151231521"></p> <blockquote><p>注意在HA架构中没有SecondaryNameNode,合并edits 文件到fsimage中的操作由NameNodeStandBy完成。</p></blockquote> <h3 id="_2-5-5-federatione高扩展"><a href="#_2-5-5-federatione高扩展" class="header-anchor">#</a> 2.5.5 Federatione高扩展</h3> <p>高扩展一般和HA联合起来使用。高扩展带来的好处。</p> <ol><li>HDFS集群扩展性。多个NameNode分管一部分目录，使得一个集群可以扩展到更多节点，不再因内存的限制制约文件存储数目。</li> <li>性能更高效。多个NameNode管理不同的数据，且同时对外提供服务，将为用户提供更高的读写吞吐率。</li> <li>良好的隔离性。用户可根据需要将不同业务数据交由不同NameNode管理，这样不同业务之间影响很小。</li></ol> <p><img src="/blog/Hadoop%E7%94%9F%E6%80%81%E4%BD%93%E7%B3%BB.assets/image-20220110151427216.png" alt="image-20220110151427216"></p></div></section> <footer class="page-edit"><!----> <!----></footer> <div class="page-nav"><p class="inner"><span class="prev"><a href="/blog/handbook/bigdata/hadoop.html" class="prev">
          第一章 Hadoop
        </a></span> <span class="next"><a href="/blog/handbook/bigdata/mapreduce.html">
          第三章 MapReduce
        </a></span></p></div> <div class="comments-wrapper"><!----></div></main></div> <!----></div> <ul class="sub-sidebar sub-sidebar-wrapper" style="width:12rem;" data-v-7115df4a data-v-1c636796><li class="level-2" data-v-7115df4a><a href="/blog/handbook/bigdata/hdfs.html#_2-1-hdfs-介绍" class="sidebar-link reco-side-_2-1-hdfs-介绍" data-v-7115df4a>2.1 HDFS 介绍</a></li><li class="level-2" data-v-7115df4a><a href="/blog/handbook/bigdata/hdfs.html#_2-2-hdfs-基础操作" class="sidebar-link reco-side-_2-2-hdfs-基础操作" data-v-7115df4a>2.2 HDFS 基础操作</a></li><li class="level-2" data-v-7115df4a><a href="/blog/handbook/bigdata/hdfs.html#_2-3-java操作hdfs" class="sidebar-link reco-side-_2-3-java操作hdfs" data-v-7115df4a>2.3 Java操作HDFS</a></li><li class="level-2" data-v-7115df4a><a href="/blog/handbook/bigdata/hdfs.html#_2-4-hdfs核心进程" class="sidebar-link reco-side-_2-4-hdfs核心进程" data-v-7115df4a>2.4 HDFS核心进程</a></li><li class="level-3" data-v-7115df4a><a href="/blog/handbook/bigdata/hdfs.html#_2-4-1-namenode" class="sidebar-link reco-side-_2-4-1-namenode" data-v-7115df4a>2.4.1 NameNode</a></li><li class="level-3" data-v-7115df4a><a href="/blog/handbook/bigdata/hdfs.html#_2-4-2-secondarynamenode" class="sidebar-link reco-side-_2-4-2-secondarynamenode" data-v-7115df4a>2.4.2 SecondaryNameNode</a></li><li class="level-3" data-v-7115df4a><a href="/blog/handbook/bigdata/hdfs.html#_2-4-3-datanode" class="sidebar-link reco-side-_2-4-3-datanode" data-v-7115df4a>2.4.3 DataNode</a></li><li class="level-3" data-v-7115df4a><a href="/blog/handbook/bigdata/hdfs.html#_2-4-4-总结" class="sidebar-link reco-side-_2-4-4-总结" data-v-7115df4a>2.4.4 总结</a></li><li class="level-2" data-v-7115df4a><a href="/blog/handbook/bigdata/hdfs.html#_2-5hdfs-高级" class="sidebar-link reco-side-_2-5hdfs-高级" data-v-7115df4a>2.5HDFS 高级</a></li><li class="level-3" data-v-7115df4a><a href="/blog/handbook/bigdata/hdfs.html#_2-5-1-hdfs的回收站" class="sidebar-link reco-side-_2-5-1-hdfs的回收站" data-v-7115df4a>2.5.1 HDFS的回收站</a></li><li class="level-3" data-v-7115df4a><a href="/blog/handbook/bigdata/hdfs.html#_2-5-2-hdfs的安全模式" class="sidebar-link reco-side-_2-5-2-hdfs的安全模式" data-v-7115df4a>2.5.2 HDFS的安全模式</a></li><li class="level-3" data-v-7115df4a><a href="/blog/handbook/bigdata/hdfs.html#_2-5-3-实时上传数据至hdfs" class="sidebar-link reco-side-_2-5-3-实时上传数据至hdfs" data-v-7115df4a>2.5.3 实时上传数据至HDFS</a></li><li class="level-3" data-v-7115df4a><a href="/blog/handbook/bigdata/hdfs.html#_2-5-4-ha-高可用" class="sidebar-link reco-side-_2-5-4-ha-高可用" data-v-7115df4a>2.5.4 HA 高可用</a></li><li class="level-3" data-v-7115df4a><a href="/blog/handbook/bigdata/hdfs.html#_2-5-5-federatione高扩展" class="sidebar-link reco-side-_2-5-5-federatione高扩展" data-v-7115df4a>2.5.5 Federatione高扩展</a></li></ul></div></div></div><div class="global-ui"><div class="back-to-ceiling" style="right:1rem;bottom:6rem;width:2.5rem;height:2.5rem;border-radius:.25rem;line-height:2.5rem;display:none;" data-v-65133105 data-v-65133105><svg t="1574745035067" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="5404" class="icon" data-v-65133105><path d="M526.60727968 10.90185116a27.675 27.675 0 0 0-29.21455937 0c-131.36607665 82.28402758-218.69155461 228.01873535-218.69155402 394.07834331a462.20625001 462.20625001 0 0 0 5.36959153 69.94390903c1.00431239 6.55289093-0.34802892 13.13561351-3.76865779 18.80351572-32.63518765 54.11355614-51.75690182 118.55860487-51.7569018 187.94566865a371.06718723 371.06718723 0 0 0 11.50484808 91.98906777c6.53300375 25.50556257 41.68394495 28.14064038 52.69160883 4.22606766 17.37162448-37.73630017 42.14135425-72.50938081 72.80769204-103.21549295 2.18761121 3.04276886 4.15646224 6.24463696 6.40373557 9.22774369a1871.4375 1871.4375 0 0 0 140.04691725 5.34970492 1866.36093723 1866.36093723 0 0 0 140.04691723-5.34970492c2.24727335-2.98310674 4.21612437-6.18497483 6.3937923-9.2178004 30.66633723 30.70611158 55.4360664 65.4791928 72.80769147 103.21549355 11.00766384 23.91457269 46.15860503 21.27949489 52.69160879-4.22606768a371.15156223 371.15156223 0 0 0 11.514792-91.99901164c0-69.36717486-19.13165746-133.82216804-51.75690182-187.92578088-3.42062944-5.66790279-4.76302748-12.26056868-3.76865837-18.80351632a462.20625001 462.20625001 0 0 0 5.36959269-69.943909c-0.00994388-166.08943902-87.32547796-311.81420293-218.6915546-394.09823051zM605.93803103 357.87693858a93.93749974 93.93749974 0 1 1-187.89594924 6.1e-7 93.93749974 93.93749974 0 0 1 187.89594924-6.1e-7z" p-id="5405" data-v-65133105></path><path d="M429.50777625 765.63860547C429.50777625 803.39355007 466.44236686 1000.39046097 512.00932183 1000.39046097c45.56695499 0 82.4922232-197.00623328 82.5015456-234.7518555 0-37.75494459-36.9345906-68.35043303-82.4922232-68.34111062-45.57627738-0.00932239-82.52019037 30.59548842-82.51086798 68.34111062z" p-id="5406" data-v-65133105></path></svg></div><canvas id="vuepress-canvas-cursor"></canvas><div id="live2d-widget" class="live2d-widget-container" style="position:fixed;right:50px;bottom:-70px;width:135px;height:300px;z-index:99999;opacity:0.8;pointer-events:none;"><canvas id="live2d_canvas" width="135" height="300" class="live2d_canvas" style="position:absolute;left:0px;top:0px;width:135px;height:300px;"></canvas></div></div></div>
    <script src="/blog/assets/js/app.f600c34c.js" defer></script><script src="/blog/assets/js/3.1aae9359.js" defer></script><script src="/blog/assets/js/1.ae8a88ec.js" defer></script><script src="/blog/assets/js/44.e50bce95.js" defer></script>
  </body>
</html>
